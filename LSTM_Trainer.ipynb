{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LSTM_Trainer.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VindhyaSRajan/Guided-Research/blob/master/LSTM_Trainer.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cn6jbVFyD33q",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "08f621b6-2aeb-4a74-e5c3-e7390f1dbc0e"
      },
      "source": [
        "!pip install nltk"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rEgT-P_WD9M7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "59878d55-49dd-4785-e702-8bd3c68fbb73"
      },
      "source": [
        "#installing all the libraries needed for the task\n",
        "import pandas as pd\n",
        "import json\n",
        "import nltk\n",
        "from pandas.io.json import json_normalize\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import re  \n",
        "from nltk.corpus import stopwords\n",
        "stops1 = set(stopwords.words(\"english\"))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rSS00LwXD9TR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "6a979622-2403-4445-b276-66276760de81"
      },
      "source": [
        "! pip install gensim\n",
        "! pip install seaborn\n",
        "! pip install elasticsearch\n",
        "! pip install esengine\n",
        "! pip install ipdb"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.6/dist-packages (3.6.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.17.4)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.12.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.3.3)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.6/dist-packages (from gensim) (1.9.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (1.10.36)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.21.0)\n",
            "Requirement already satisfied: boto>=2.32 in /usr/local/lib/python3.6/dist-packages (from smart-open>=1.2.1->gensim) (2.49.0)\n",
            "Requirement already satisfied: botocore<1.14.0,>=1.13.36 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (1.13.36)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.2.1)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->smart-open>=1.2.1->gensim) (0.9.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (1.24.3)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2019.11.28)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->smart-open>=1.2.1->gensim) (2.8)\n",
            "Requirement already satisfied: python-dateutil<2.8.1,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->smart-open>=1.2.1->gensim) (2.6.1)\n",
            "Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.14.0,>=1.13.36->boto3->smart-open>=1.2.1->gensim) (0.15.2)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.6/dist-packages (0.9.0)\n",
            "Requirement already satisfied: scipy>=0.14.0 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.3.3)\n",
            "Requirement already satisfied: pandas>=0.15.2 in /usr/local/lib/python3.6/dist-packages (from seaborn) (0.25.3)\n",
            "Requirement already satisfied: matplotlib>=1.4.3 in /usr/local/lib/python3.6/dist-packages (from seaborn) (3.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.3 in /usr/local/lib/python3.6/dist-packages (from seaborn) (1.17.4)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.15.2->seaborn) (2.6.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas>=0.15.2->seaborn) (2018.9)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib>=1.4.3->seaborn) (2.4.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas>=0.15.2->seaborn) (1.12.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from kiwisolver>=1.0.1->matplotlib>=1.4.3->seaborn) (42.0.2)\n",
            "Collecting elasticsearch\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/3c/047e4985f81af98b71f19e318a6207187987bcd8af73b1edd4470cdee76b/elasticsearch-7.1.0-py2.py3-none-any.whl (83kB)\n",
            "\u001b[K     |████████████████████████████████| 92kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: urllib3>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from elasticsearch) (1.24.3)\n",
            "Installing collected packages: elasticsearch\n",
            "Successfully installed elasticsearch-7.1.0\n",
            "Collecting esengine\n",
            "  Downloading https://files.pythonhosted.org/packages/fa/33/27b907a0fb53b7ba78843569009150dd004f79c0e6d34553caf9af2cde65/esengine-0.1.0-py2.py3-none-any.whl\n",
            "Collecting six==1.10.0\n",
            "  Downloading https://files.pythonhosted.org/packages/c8/0a/b6723e1bc4c516cb687841499455a8505b44607ab535be01091c0f24f079/six-1.10.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from esengine) (2.6.1)\n",
            "\u001b[31mERROR: google-colab 1.0.0 has requirement six~=1.12.0, but you'll have six 1.10.0 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: datascience 0.10.6 has requirement folium==0.2.1, but you'll have folium 0.8.3 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: albumentations 0.1.12 has requirement imgaug<0.2.7,>=0.2.5, but you'll have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Installing collected packages: six, esengine\n",
            "  Found existing installation: six 1.12.0\n",
            "    Uninstalling six-1.12.0:\n",
            "      Successfully uninstalled six-1.12.0\n",
            "Successfully installed esengine-0.1.0 six-1.10.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "six"
                ]
              }
            }
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Collecting ipdb\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/01/27427b1f4a97455b345297a48761544bc8e7fb1f3aef6904ec86ddf75f65/ipdb-0.12.3.tar.gz\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from ipdb) (42.0.2)\n",
            "Requirement already satisfied: ipython>=5.1.0 in /usr/local/lib/python3.6/dist-packages (from ipdb) (5.5.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (1.0.18)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (0.7.5)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (4.7.0)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (4.4.1)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (2.1.3)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (0.8.1)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.6/dist-packages (from ipython>=5.1.0->ipdb) (4.3.3)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.1.0->ipdb) (1.10.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=5.1.0->ipdb) (0.1.7)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=5.1.0->ipdb) (0.6.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.2->ipython>=5.1.0->ipdb) (0.2.0)\n",
            "Building wheels for collected packages: ipdb\n",
            "  Building wheel for ipdb (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ipdb: filename=ipdb-0.12.3-cp36-none-any.whl size=9223 sha256=a24c1a3e7418c3e05b136d771bb59a071040b58615902d10012af024a4d80efc\n",
            "  Stored in directory: /root/.cache/pip/wheels/57/43/c5/614153606de8f5e358e266723f53254e70752f4ffc8c85ec63\n",
            "Successfully built ipdb\n",
            "Installing collected packages: ipdb\n",
            "Successfully installed ipdb-0.12.3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4OMQZhZ6IjsM",
        "colab_type": "code",
        "outputId": "f3608f8d-105d-4509-8f0b-efd07190d626",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4iy4p3RwD9Zb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from preprocess import *\n",
        "from sub_find import *\n",
        "from true_subs import *\n",
        "from constants import *\n",
        "# from graph_evaluation import *\n",
        "from Vocabulary import Vocab\n",
        "import pickle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gWl2P10KD9by",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from recipe import Recipe\n",
        "def load_data_from_file(filename=None, ing_file_name=None, local=True, save=False):\n",
        "    return load_data(file_name=filename, ing_file_name=ing_file_name, local=local, save=save)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ULpuFajdD9gt",
        "colab_type": "code",
        "outputId": "0832e0a7-9e50-4cd9-a088-c0c88ebafe87",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import os\n",
        "#os.chdir('raw_data')\n",
        "recipes = load_data_from_file(\"100ksample\", ing_file_name = \"dbpedia_ingredients.txt\",local=True, save=False )\n",
        "clean_recipes = [x.proccessed_ing_list for x in recipes]\n",
        "recipes = load_data_from_file(\"100ksample2\", \"dbpedia_ingredients.txt\")\n",
        "sample100k2 = [x.proccessed_ing_list for x in recipes]\n",
        "clean_recipes.extend(sample100k2) \n",
        "type(clean_recipes)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "list"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0FVK71ED9lX",
        "colab_type": "code",
        "outputId": "25972912-e6df-4cd2-8476-7aed25a11d51",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# currently looking only on the second set of elements\n",
        "#TO-DO : Currently doing it for 100k samples, will later move this to 1M recipes\n",
        "total_number_of_recipes = len(recipes)\n",
        "print(total_number_of_recipes)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6En1OxhVD9qn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "titles_present = set()\n",
        "for reduced_recipe_object in recipes:\n",
        "  titles_present.add(str(reduced_recipe_object.id))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K3mfDrQfD9u6",
        "colab_type": "code",
        "outputId": "8c823e58-044a-4aba-b8ab-900e49cf30f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        }
      },
      "source": [
        "vars(recipes[0])"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'id': 'Cajun Spice Blend',\n",
              " 'ingredients_text': '1 tablespoon garlic powder 1 tablespoon onion powder 1 tablespoon sugar 1 teaspoon salt 1 teaspoon pepper 1 teaspoon dried basil 1 teaspoon paprika 12 teaspoon cayenne pepper',\n",
              " 'instructions_text': 'mix together and store in airtight container and use as wanted.',\n",
              " 'proccessed_ing_list': ['garlic powder',\n",
              "  'onion powder',\n",
              "  'sugar',\n",
              "  'cayenne pepper'],\n",
              " 'title': 'Cajun Spice Blend'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bsLZ2Ky1D9tk",
        "colab_type": "code",
        "outputId": "96699cc5-abce-4a18-b4c8-a920b1a719f5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "final_dataset = [(x.proccessed_ing_list, x.id) for x in recipes]\n",
        "final_dataset[0]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['garlic powder', 'onion powder', 'sugar', 'cayenne pepper'],\n",
              " 'Cajun Spice Blend')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AgvQlg8yD9o6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.stem import PorterStemmer\n",
        "stemmer = PorterStemmer()\n",
        "# type(titles_present)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JhU_p9ZkD9jz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def stem_title(word):\n",
        "    return stemmer.stem(word)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4mMOE8qjD9fP",
        "colab_type": "code",
        "outputId": "1b30a826-aa54-45c7-939b-73249839f512",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# an example\n",
        "stem_title('Carsons Chicken Wellington W/ Exotic Mushroom Sherry Sauce')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'carsons chicken wellington w/ exotic mushroom sherry sauc'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7IetfZWkD9Xm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "updated_title = [stem_title(title) for title in titles_present]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ltz6jXRnEoTc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('recipe_titles_stemmed.txt', 'w') as file:\n",
        "     for item in updated_title:\n",
        "         file.write(\"%s\\n\" % item)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tCoThQbOErga",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "my_list = 'cake,pasta,custard,rolls,stew,casserole,sauce,soup,burgers,pizza,salad,muffins,steaks,fish,ham'.split(\",\") # Do Not Run"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o4gFUccHEroA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vindhya_list = ['Cake', 'Salad', 'Noodles', 'Hummus', 'Burger', 'Steak', 'Pie', 'Chicken', 'Custard', 'Chips',\n",
        "                'Casserole', 'Pasta', 'Pizza', 'Omelette', 'soup', 'sauce'] #Do Not Run"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4vuH9axo1FjY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vindhya_map = {\n",
        "    'Soup' : ['Soup'],\n",
        "    'Sandwich' : ['Sandwich'],\n",
        "    'Cocktail' : ['Cocktail'],\n",
        "    'Pudding' : ['Pudding'],\n",
        "    'Wraps' : ['Wraps'],\n",
        "    'Doughnut' : ['Doughnut'],\n",
        "    'Bread' : ['Bread'],\n",
        "    'Smoothie' : ['Smoothie'],\n",
        "    'Sorbet' : ['Sorbet'],\n",
        "    'Stew' : [\"Daal\", \"Chili\", \"Goulash\", \"Stew\"],\n",
        "    'Cake' :[\"Muffin\", \"Cake\"],\n",
        "    'Condiments' : [\"Pickles\", \"Sauce\"],\n",
        "    'Taco' : [\"Quessidila\", \"Fajitas\", \"Taco\"],\n",
        "    'Salad' : [\"Guacamole\", \"Salad\"],\n",
        "    'Noodles' : [\"Noodles\"],\n",
        "    'Hummus' : ['Hummus'],\n",
        "    'Burger' : ['Burger'],\n",
        "    'Steak' : ['Steak'],\n",
        "    'Pie' : ['Pie'],\n",
        "    'Custard' : ['Custard'],\n",
        "    'Chips' : ['Chips'],\n",
        "    'Casserole' : ['Casserole'],\n",
        "    'Pasta' : ['Pasta'],\n",
        "    'Pizza' : ['Pizza'],\n",
        "    'Omelette' : ['Omelette'],\n",
        "    'Chicken' : ['Chicken'],\n",
        "    'Beef' : ['Beef'],\n",
        "    'Spring Roll' : ['Spring Roll'],\n",
        "    'Pancake' : ['Pancake'],\n",
        "    'Pastry' : ['Pastry'],\n",
        "    'Salmon' : ['Salmon'],\n",
        "    'Spread' : ['Spread']\n",
        "    \n",
        "}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FhWNGJg1VC7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vindhya_map = dict((stemmer.stem(k), list(map(stemmer.stem, v))) for k, v in vindhya_map.items())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K6ZBrOyk1YU1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import itertools\n",
        "all_recipe_list = list(itertools.chain(*vindhya_map.values()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xX8eOUaa1dSR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef4bf065-2cf6-4816-fc4e-0c0dc0239fce"
      },
      "source": [
        "# check if the recipe matches\n",
        "# https://stackoverflow.com/questions/6531482/how-to-check-if-a-string-contains-an-element-from-a-list-in-python\n",
        "counter = 0\n",
        "list(itertools.chain(*vindhya_map.values()))\n",
        "for reduced_recipe_object in recipes:\n",
        "    # Honestly this is a shitty attempt since I already did the stemming earlier\n",
        "    # however, I am doing the same again\n",
        "    counter = counter +  any (stem_title(title) in stem_title(reduced_recipe_object.id) for title in all_recipe_list)\n",
        "    \n",
        "counter"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "43586"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwddCq3Z1hKM",
        "colab_type": "text"
      },
      "source": [
        "The next 2 cells need not to be run now. The version is updated with the grouped categories."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ttkcSrTNbuln",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Updated the list now. Run this cell only\n",
        "vindhya_list = ['Cake', 'Salad', 'Noodles', 'Hummus', 'Burger', 'Steak', 'Pie', 'Custard', 'Chips', 'Casserole', 'Pasta', 'Pizza', 'Omelette', 'Soup', 'Sauce','Sandwich','Muffin','Pickles','Cocktail','Pudding','Wraps','Taco','Daal','Guacamole','Doughnut','Bread','Smoothie','Sorbet','Chili','Stew','Chicken','Beef',]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SUXQVY9hErt4",
        "colab_type": "code",
        "outputId": "a45c32ac-c3a4-433e-8222-2e8794e375b4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# check if the recipe matches\n",
        "# https://stackoverflow.com/questions/6531482/how-to-check-if-a-string-contains-an-element-from-a-list-in-python\n",
        "counter = 0\n",
        "for reduced_recipe_object in recipes:\n",
        "    # Honestly this is a shitty attempt since I already did the stemming earlier\n",
        "    # however, I am doing the same again\n",
        "    counter = counter +  any (stem_title(title) in stem_title(reduced_recipe_object.id) for title in vindhya_list)\n",
        "    \n",
        "counter"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "41942"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k8kYnw7JErzx",
        "colab_type": "code",
        "outputId": "05c5a6fb-b8e0-47bd-fc17-12d82ad394ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "percentage_covered = counter / total_number_of_recipes * 100\n",
        "print(percentage_covered)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "43.586000000000006\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HPAw17tEEr51",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# so sample 100k2 as we are working on the clean_recipes\n",
        "final_dataset = [(x.proccessed_ing_list, x.id) for x in recipes]\n",
        "only_ingredients = [i[0] for i in final_dataset]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vO62rCHKEr-t",
        "colab_type": "code",
        "outputId": "b5792ed0-238e-4ef7-dd73-c1fb1dfb06cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "type(final_dataset[0]) #should be a tuple"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tuple"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y4zXAq0ZEr9C",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "ingredient_vocabulary = Vocab()\n",
        "for recipe in only_ingredients:\n",
        "    for ingredients in recipe:\n",
        "        ingredient_vocabulary.add_word(ingredients)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j9ReduXHEr3h",
        "colab_type": "code",
        "outputId": "ed34864f-0cd9-48f8-e37c-be0ac59b140b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Let us see the vocabulary size once\n",
        "ingredient_vocabulary.max_idx"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1152"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bx1YE_5IErxy",
        "colab_type": "code",
        "outputId": "3fa0d409-85ec-4d11-f6e9-9f96bc35b91a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "ingredient_vocabulary.get_word(1151)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'crocus'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0-uLbhZAErsM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.DataFrame(final_dataset, columns =['Ingredients', 'Recipe_id'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tD82AjNtcloC",
        "colab_type": "code",
        "outputId": "1852e063-7725-46de-c35b-79f6440ab094",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "df[df.Recipe_id == 'Peanut Butter Pie']\n",
        "df.shape"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(100000, 2)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "le_mUuOdcyGa",
        "colab_type": "code",
        "outputId": "9668bd83-0295-4c66-b7f4-46e9e7bce65b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "#Merging the two pandas df to create the one for just 100 samples per category\n",
        "df2  = pd.read_csv('/content/Food_Categories_100PerCat.csv')\n",
        "df2.head()\n",
        "#df[df.Recipe_id == 'Screwdriver Cocktail'] #Just a sanity check that we have all the recipes in both the data frames to join by\n",
        "df2['Recipe_id'] = df2.Recipe_Title.values\n",
        "df2.head()\n",
        "df = df.merge(df2,on = 'Recipe_id')\n",
        "print(df.shape)\n",
        "print(df.columns)\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3278, 4)\n",
            "Index(['Ingredients', 'Recipe_id', 'Recipe_Title', 'Food_Category'], dtype='object')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d1oMcHWNFUgt",
        "colab_type": "code",
        "outputId": "30b3c5f7-247a-440b-dc74-2dce78d00dc6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 605
        }
      },
      "source": [
        "#Sanity Check to see if all recipe categories are avaialable\n",
        "print(df.shape)\n",
        "df['COUNTER'] = 1\n",
        "grouped_data = df.groupby(['Food_Category'])['COUNTER'].sum()\n",
        "grouped_data"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(3278, 4)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Food_Category\n",
              "Beef         102\n",
              "Bread        112\n",
              "Burger       105\n",
              "Cake         108\n",
              "Casserole    113\n",
              "Chicken      106\n",
              "Chili        103\n",
              "Chips        114\n",
              "Cocktail     106\n",
              "Custard      104\n",
              "Daal           4\n",
              "Doughnuts     71\n",
              "Guacamole    127\n",
              "Hummus       118\n",
              "Muffins      105\n",
              "Noodles      101\n",
              "Omelette      72\n",
              "Pasta        100\n",
              "Pickle       109\n",
              "Pie          115\n",
              "Pizza        114\n",
              "Pudding      108\n",
              "Salad        106\n",
              "Sandwich     100\n",
              "Sauce        109\n",
              "Smoothie     108\n",
              "Sorbet       108\n",
              "Soup         107\n",
              "Steak        103\n",
              "Stew         106\n",
              "Taco         105\n",
              "Wrap         109\n",
              "Name: COUNTER, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMKd9XGyibSB",
        "colab_type": "code",
        "outputId": "194df49f-4e0d-41dc-b0ec-4af51ee1e006",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 279
        }
      },
      "source": [
        "#Since we have all food categories, let's drop the unecessary columns and have one final df\n",
        "df = df.drop(columns = ['Recipe_Title', 'Food_Category','COUNTER'])\n",
        "print(df.columns)\n",
        "print(df.shape)\n",
        "print('----After Dropping unwanted columns----')\n",
        "print(df.columns)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Index(['Ingredients', 'Recipe_id'], dtype='object')\n",
            "(3278, 2)\n",
            "----After Dropping unwanted columns----\n",
            "Index(['Ingredients', 'Recipe_id'], dtype='object')\n",
            "(3278, 2)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Ingredients</th>\n",
              "      <th>Recipe_id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>[cream cheese, condensed milk, peanut butter, ...</td>\n",
              "      <td>Peanut Butter Pie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>[chocolate, sugar, butter, cream cheese, peanu...</td>\n",
              "      <td>Peanut Butter Pie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>[graham cracker, peanut butter, butter, cream ...</td>\n",
              "      <td>Peanut Butter Pie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>[graham cracker crust, cream cheese, peanut bu...</td>\n",
              "      <td>Peanut Butter Pie</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>[cream cheese, peanut butter, sugar, milk, hea...</td>\n",
              "      <td>Peanut Butter Pie</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                         Ingredients          Recipe_id\n",
              "0  [cream cheese, condensed milk, peanut butter, ...  Peanut Butter Pie\n",
              "1  [chocolate, sugar, butter, cream cheese, peanu...  Peanut Butter Pie\n",
              "2  [graham cracker, peanut butter, butter, cream ...  Peanut Butter Pie\n",
              "3  [graham cracker crust, cream cheese, peanut bu...  Peanut Butter Pie\n",
              "4  [cream cheese, peanut butter, sugar, milk, hea...  Peanut Butter Pie"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "52DcKq7kFUlx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is more of a hack\n",
        "def recipe_vocab_on_list(ingedient_list):\n",
        "    result_list = []\n",
        "    for ingedient in ingedient_list:\n",
        "        result_list.append(ingredient_vocabulary.get_idx(ingedient))\n",
        "    return result_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nIEIatkUFUrl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Ingredient_Numeric'] = df.Ingredients.apply(recipe_vocab_on_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5OXf6D0IFUpl",
        "colab_type": "code",
        "outputId": "4ad17b1d-8d60-4f4c-ed62-1e667f0e3d76",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "df.iloc[5]"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ingredients           [orange, clove, apple, water, cinnamon]\n",
              "Recipe_id                            The Spiced Cider Project\n",
              "Ingredient_Numeric                       [27, 28, 29, 24, 30]\n",
              "Recipe_id_numeric                                           0\n",
              "Name: 5, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZnivzJXfjLwK",
        "colab_type": "code",
        "outputId": "cc531b92-86c1-40cf-8312-49188a143710",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "%pwd"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xIJ1r41HT17r",
        "colab_type": "code",
        "outputId": "a253feab-6cc2-497c-d539-ef3fd917ccc3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "!unzip '/content/glove.6B.100d.txt.zip'"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/glove.6B.100d.txt.zip\n",
            "  inflating: glove.6B.100d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HRyh_bVMToTE",
        "colab_type": "code",
        "outputId": "d4e2feaa-0ac0-4116-bff4-a6dd000899e3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "from gensim.test.utils import datapath\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "glove_file = datapath('/content/glove.6B.100d.txt')\n",
        "with open('glove.100d.w2v', mode='wb+') as dest_file:\n",
        "    glove2word2vec(glove_file, dest_file)"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vHq2mc4ZT9CS",
        "colab_type": "code",
        "outputId": "1d2e2d7e-f649-41a2-c7ea-35c9991ee1e8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 70
        }
      },
      "source": [
        "import gensim\n",
        "pretrained_embedding = gensim.models.KeyedVectors.load_word2vec_format('/content/glove.100d.w2v')"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:402: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cY4zwEdhT-YF",
        "colab_type": "code",
        "outputId": "d3e832d4-f428-4e61-ebcf-1082e44615ad",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "# Just a sample check to indicate things are working as expected\n",
        "pretrained_embedding.vocab['salmon'].index "
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7411"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XPYPet5UEPQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is more of a hack\n",
        "def recipe_vocab_on_list(ingedient_list):\n",
        "    result_list = []\n",
        "    for ingedient in ingedient_list:\n",
        "        # If multi word ingredient, chose the first word\n",
        "        ingedient = ingedient.split(\" \")[0]\n",
        "        try:\n",
        "            result_list.append(pretrained_embedding.vocab[ingedient].index)\n",
        "        except KeyError:\n",
        "            result_list.append(pretrained_embedding.vocab['unk'].index)\n",
        "    return result_list"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VStwgie6UJgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Ingredient_Numeric'] = df.Ingredients.apply(recipe_vocab_on_list)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lNIOX00mUM8m",
        "colab_type": "code",
        "outputId": "ce89a673-dee0-4cd2-e2f1-790dec2a8115",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "df.iloc[5]"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ingredients           [orange, clove, apple, water, cinnamon]\n",
              "Recipe_id                            The Spiced Cider Project\n",
              "Ingredient_Numeric            [3200, 33170, 3292, 430, 17773]\n",
              "Recipe_id_numeric                                           0\n",
              "Name: 5, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKApPqzEFUj6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "recipe_vocabulary = Vocab()\n",
        "for recipe in vindhya_map:\n",
        "    recipe_vocabulary.add_word(stemmer.stem(recipe))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4CpsErILFUeO",
        "colab_type": "code",
        "outputId": "5bc20705-4a37-484a-9e4c-bf0494afeaac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 54
        }
      },
      "source": [
        "recipe_vocabulary"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'<UNK>': 0, 'soup': 1, 'sandwich': 2, 'cocktail': 3, 'pud': 4, 'wrap': 5, 'doughnut': 6, 'bread': 7, 'smoothi': 8, 'sorbet': 9, 'stew': 10, 'cake': 11, 'condiment': 12, 'taco': 13, 'salad': 14, 'noodl': 15, 'hummu': 16, 'burger': 17, 'steak': 18, 'pie': 19, 'custard': 20, 'chip': 21, 'casserol': 22, 'pasta': 23, 'pizza': 24, 'omelett': 25, 'chicken': 26, 'beef': 27, 'spring rol': 28, 'pancak': 29, 'pastri': 30, 'salmon': 31, 'spread': 32}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W6bZg1A7FUcZ",
        "colab_type": "code",
        "outputId": "8bf87ec8-223f-4b31-ca84-9d7a97ccd6f7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(recipe_vocabulary.word_2_idx)"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "97OhTN_8FUZa",
        "colab_type": "code",
        "outputId": "9745c9cd-9eb9-4725-c597-4383099464e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "recipe_vocabulary.check_any_word_in_vocab(stemmer.stem('The Spiced Cake Project'))\n",
        "# recipe_vocabulary.get_idx('cake')"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(True, 'cake')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I8yKd_FxUfwN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Uptil this point we were simply returning the first match in the recipe vocabulary. \n",
        "# This can be modified and we look for all the matches of possible recipe\n",
        "# Since the list is sorted specific to our rule, we would go ahead and take the minimum value from all\n",
        "def get_recipe_idx(recipe):\n",
        "    recipe_stemmed = stemmer.stem(recipe)\n",
        "    lookup_result = recipe_vocabulary.get_all_words_in_vocab(recipe_stemmed)\n",
        "    #lookup_result = Vocab.get_all_words_in_vocab(recipe_stemmed)\n",
        "    if lookup_result[0]:\n",
        "        print(lookup_result[1])\n",
        "        return min(lookup_result[1])\n",
        "    # No match so 0 returned\n",
        "    return  0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CxMQIUEyFrdi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# def get_recipe_idx(recipe):\n",
        "#     recipe_stemmed = stemmer.stem(recipe)\n",
        "#     lookup_result = recipe_vocabulary.check_any_word_in_vocab(recipe_stemmed)\n",
        "#     if lookup_result[0]:\n",
        "#         return recipe_vocabulary.get_idx(lookup_result[1])\n",
        "#     return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HkibAbCkFrj2",
        "colab_type": "code",
        "outputId": "b5bd5b3e-d8f2-4c15-d75b-e2eeadfaca90",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "source": [
        "get_recipe_idx('The Spiced Cake Project')\n",
        "#get_recipe_idx('Sugarless Applesauce Cake')"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[11]\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "11"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o5omvChcFriG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['Recipe_id_numeric'] = df.Recipe_id.apply(get_recipe_idx)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uAyOxevUFrby",
        "colab_type": "code",
        "outputId": "2a94f1e8-b569-4aef-dca4-6c44c836cca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        }
      },
      "source": [
        "df.iloc[54]"
      ],
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Ingredients           [seed, fruit, water, flour, baking soda, nutme...\n",
              "Recipe_id                                     Sugarless Applesauce Cake\n",
              "Ingredient_Numeric    [3404, 4138, 430, 8212, 10057, 30593, 17773, 6...\n",
              "Recipe_id_numeric                                                     0\n",
              "Name: 54, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZjjkRu3BlFF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 571
        },
        "outputId": "1d678c10-13d9-4ef7-f343-74b53d86ebdf"
      },
      "source": [
        "#Just Checking here that all categories have some data in them\n",
        "df['COUNTER'] = 1\n",
        "group_data = df.groupby(['Recipe_id_numeric'])['COUNTER'].sum()\n",
        "group_data"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Recipe_id_numeric\n",
              "0     67055\n",
              "1      3468\n",
              "2      1097\n",
              "3       309\n",
              "4       605\n",
              "5       234\n",
              "6        62\n",
              "7      2325\n",
              "8       405\n",
              "9       115\n",
              "10      788\n",
              "11      950\n",
              "13      487\n",
              "14     5729\n",
              "15      218\n",
              "16       94\n",
              "17       84\n",
              "18      797\n",
              "19      791\n",
              "20      191\n",
              "21      817\n",
              "22     1485\n",
              "23     1260\n",
              "24      992\n",
              "25       40\n",
              "26     6552\n",
              "27     1448\n",
              "29      416\n",
              "30       69\n",
              "31      842\n",
              "32      275\n",
              "Name: COUNTER, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 118
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H8xRKXWEB7oE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "598068e1-9dee-45ee-811d-460bc51ac85e"
      },
      "source": [
        "df = df.drop(columns= ['COUNTER'])\n",
        "df.columns"
      ],
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Ingredients', 'Recipe_id', 'Ingredient_Numeric', 'Recipe_id_numeric'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 127
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BFO0mAONFrZs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.Recipe_id_numeric.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "phrkhbPDFrXb",
        "colab_type": "code",
        "outputId": "305296db-40dc-400f-c864-21b7bb273202",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(df)"
      ],
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "100000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 128
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfsJHPdmFrT7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with open('vocab_clubbed_33.pkl','wb') as file:\n",
        "    pickle.dump(recipe_vocabulary, file)\n",
        "    pickle.dump(ingredient_vocabulary, file)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K1fGdcgSF_UV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def check_empty(x):\n",
        "    return len(x) == 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w-gAcb4MF_ZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "processed_df = df.drop(df[df.Ingredient_Numeric.apply(check_empty)].index)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0UPKTxzOF_fm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "assert sum(processed_df.Ingredient_Numeric.apply(check_empty)) == 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iF5OWlWzF_c6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# I am just saving the file here for reference later\n",
        "pd.to_pickle(processed_df, './processed_df_clubbed_33.pkl')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TPrIGmstF_Xa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "df_train, df_test = train_test_split(processed_df, test_size = 0.2, random_state = 0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUOtDzaXF_SA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# I am assuming that we are able to get the categories here\n",
        "# Now this should become a LSTM based model which will try and do binary prediction\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.utils.data as data\n",
        "import torch.utils.data.dataloader as dataloader\n",
        "from torch.nn.utils.rnn import pad_sequence"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9blkiLEqF_O1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# Some constants\n",
        "batch_size = 5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oBeuqchJGXCG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://github.com/yunjey/seq2seq-dataloader/blob/master/data_loader.py\n",
        "def collate_fn(data):\n",
        "    \"\"\"Creates mini-batch tensors from the list of tuples (src_seq, trg_seq).\n",
        "    We should build a custom collate_fn rather than using default collate_fn,\n",
        "    because merging sequences (including padding) is not supported in default.\n",
        "    Seqeuences are padded to the maximum length of mini-batch sequences (dynamic padding).\n",
        "    Args:\n",
        "        data: list of tuple (src_seq, trg_seq).\n",
        "            - src_seq: torch tensor of shape (?); variable length.\n",
        "            - trg_seq: torch tensor of shape (?); variable length.\n",
        "    Returns:\n",
        "        src_seqs: torch tensor of shape (batch_size, padded_length).\n",
        "        src_lengths: list of length (batch_size); valid length for each padded source sequence.\n",
        "        trg_seqs: torch tensor of shape (batch_size, padded_length).\n",
        "        trg_lengths: list of length (batch_size); valid length for each padded target sequence.\n",
        "    \"\"\"\n",
        "    def merge(sequences):\n",
        "        lengths = [len(seq) for seq in sequences]\n",
        "        padded_seqs = torch.zeros(len(sequences), max(lengths)).long()\n",
        "        for i, seq in enumerate(sequences):\n",
        "            end = lengths[i]\n",
        "            padded_seqs[i, :end] = seq[:end]\n",
        "        return padded_seqs, lengths\n",
        "\n",
        "    # sort a list by sequence length (descending order) to use pack_padded_sequence\n",
        "#     print(data[0]) # list of tuples\n",
        "    data.sort(key=lambda x: len(x[0]), reverse=True)\n",
        "\n",
        "    # seperate source and target sequences\n",
        "    src_seqs, trg_seqs = zip(*data)\n",
        "\n",
        "    # merge sequences (from tuple of 1D tensor to 2D tensor)\n",
        "    src_seqs, src_lengths = merge(src_seqs)\n",
        "    # target sequence for us is a single tensor so we do not need to \n",
        "    # merge it\n",
        "    #trg_seqs, trg_lengths = merge(trg_seqs)\n",
        "    trg_seqs = torch.as_tensor(trg_seqs)\n",
        "    return src_seqs, src_lengths, trg_seqs #, trg_lengths"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uViJ0LlsGXVP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RecipeData(data.Dataset):\n",
        "    \n",
        "    def __init__(self, df):\n",
        "        super(RecipeData, self).__init__()\n",
        "        self.df = df\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.df)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = torch.as_tensor(self.df.Ingredient_Numeric.iloc[idx])\n",
        "        y = torch.as_tensor(self.df.Recipe_id_numeric.iloc[idx])\n",
        "        return X,y"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1wafZQQ-GXTU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset = RecipeData(df_train)\n",
        "test_dataset = RecipeData(df_test)\n",
        "train_data_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True,\n",
        "                                              collate_fn=collate_fn,\n",
        "                                               drop_last=True) # Done for cases when num_samples not exact multiple\n",
        "test_data_loader = torch.utils.data.DataLoader(dataset=test_dataset, # of the batch_size\n",
        "                                              batch_size=batch_size,\n",
        "                                              shuffle=True,\n",
        "                                              collate_fn=collate_fn,\n",
        "                                              drop_last=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gMjiO-9IGXRF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.Recipe_id_numeric[4]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZUpXBuiyGXOY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_dataset[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dOKK_Jv1GXMB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for (X,X_len,y) in train_data_loader:\n",
        "    print(X)\n",
        "    print(X_len)\n",
        "    print(y)\n",
        "    break"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D07MG56CGwnk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RBLg3jCaGwsO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class RecipePredictor(nn.Module):\n",
        "    \n",
        "    def __init__(self, vocab_size, hidden_dim, embedding_dim, batch_size, output_dim):\n",
        "        super(RecipePredictor, self).__init__()\n",
        "        self.vocab_size = vocab_size\n",
        "        self.output_dim = output_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.embedding_dim = embedding_dim\n",
        "        self.embedding = nn.Embedding(self.vocab_size, self.embedding_dim)\n",
        "        self.lstm = nn.LSTM(input_size=self.embedding_dim, hidden_size=self.hidden_dim)\n",
        "        self.batch_size = batch_size\n",
        "        self.predictor = nn.Linear(self.hidden_dim, self.output_dim)\n",
        "        self.non_linearity = nn.ReLU()\n",
        "        self.init_hidden() # TODO:  This should happen at the beginning of each epoch\n",
        "        \n",
        "    def init_hidden(self):\n",
        "        self.h_n = torch.randn(1, self.batch_size, self.hidden_dim)\n",
        "        self.c_n = torch.randn(1, self.batch_size, self.hidden_dim)\n",
        "        \n",
        "    \n",
        "    def forward(self, input_sequence, max_len):\n",
        "#         print(input_sequence)\n",
        "#         print(max_len)\n",
        "        embedded = self.embedding(input_sequence)\n",
        "        packed = nn.utils.rnn.pack_padded_sequence(embedded, max_len, batch_first=True)\n",
        "        outputs, (self.c_n, self.h_n) = self.lstm(packed, (self.c_n, self.h_n))\n",
        "        # Unpack padding\n",
        "        \"\"\"\n",
        "            Honestly, I do not know if at this point, I need the output. I would rather prefer to work with the\n",
        "            self.h_n cell and so will not `pad_padded_sequence`\n",
        "        \"\"\"\n",
        "        #outputs, _ = nn.utils.rnn.pad_packed_sequence(outputs, batch_first=True)\n",
        "        # on which output should the prediction be done?\n",
        "        # self.h_n =  num_layers, batch_size, hidden_dim\n",
        "        batch_size = self.h_n.shape[1]\n",
        "        output_predicted = self.predictor(self.h_n.reshape(batch_size, -1))\n",
        "        return output_predicted"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itwnM1ypGwqb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab_size = ingredient_vocabulary.max_idx + 1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O4pdesAOGwlT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_recipes = recipe_vocabulary.max_idx+1\n",
        "model = RecipePredictor(vocab_size=vocab_size, hidden_dim=512, embedding_dim=300, batch_size=batch_size,\n",
        "                       output_dim=num_recipes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iiWqFsyAGwig",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model(X, X_len)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJOCsvc-GwgS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lr = 1e-3\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=lr)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CgJARZ91Gwdg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_epoch = 2"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZriZhk6HGg6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Moving things to GPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PwMX-6n3HGe-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0LB7-DLXHGcM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def put_elements_to_device(a,b,c,device):\n",
        "    return a.to(device), b.to(device), c.to(device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xoxELhbcHGZK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# !pip install -q tb-nightly\n",
        "\n",
        "# Load the TensorBoard notebook extension\n",
        "%load_ext tensorboard"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJ58qOE6HGXM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from torch.utils.tensorboard import SummaryWriter\n",
        "writer = SummaryWriter()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2HAAbcc-HGTo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(len(train_data_loader) * batch_size)\n",
        "print(len(df_train))\n",
        "# Not same since we are dropping some terms which do not match up\n",
        "N_train = len(train_data_loader) * batch_size\n",
        "N_test = len(test_data_loader) * batch_size"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "At70SJY1HWgK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for epoch in range(num_epoch):\n",
        "    running_loss = 0\n",
        "    model.init_hidden()\n",
        "    for idx,(X,X_len,y) in enumerate(train_data_loader):\n",
        "        model.zero_grad()\n",
        "        X, X_len, y = put_elements_to_device(a=X, b=torch.tensor(X_len), c=y, device=device)\n",
        "        prediction = model(X, X_len)\n",
        "        loss = criterion(prediction, y)\n",
        "        loss.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "        running_loss += loss.item()\n",
        "        if idx % 100 == 0:\n",
        "            print(\"epoch {} loss {}\".format(epoch, running_loss))\n",
        "    writer.add_scalar('Loss/train', running_loss/N_train, epoch)\n",
        "    # validation set is still left to create\n",
        "    # Now to test the validation set\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    test_loss = 0\n",
        "    with torch.no_grad():\n",
        "        for idx,(X,X_len,y) in enumerate(test_data_loader):\n",
        "            X, X_len, y = put_elements_to_device(a=X, b=torch.tensor(X_len), c=y, device=device)\n",
        "            outputs = model(X,X_len)\n",
        "            loss = criterion(outputs, y)\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += X.size(0)\n",
        "            correct += (predicted == y).sum().item()\n",
        "    writer.add_scalar('Loss/train', test_loss/N_test, epoch)\n",
        "    print('Accuracy of the network on the test samples: %d %%' % (\n",
        "        100 * correct / total))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2JyLvmCHWdj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%load_ext tensorboard\n",
        "%tensorboard --logdir=runs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A8L9scIDHWbg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "torch.__version__"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5L0srLQHWYq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vindhya_data_df = pd.read_csv('./recipe_title_foodCategory.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wox8BOd_HijD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "list(set(vindhya_data_df.Food_Category))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REmKSA4kHk4t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a = [1,2,3,4,5]\n",
        "b = ['a','b','c','d','e']\n",
        "c = ['dil','me','dard','e','disco']\n",
        "sallu_bhoi = zip(a,b,c)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HXwDGxiWHpqD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "a,b,c = zip(*sallu_bhoi)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mBWk1rujHsS3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "np.asarray(a)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}